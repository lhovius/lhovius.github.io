# How Fast.ai makes deep learning fun (again)

I can't believe I've been learning Data Science since 2017 and still know so very little. What have I been doing all this time?
Well, not to excuse myself entirely, a large part is definitely due to how Data Science is taught. Looking back, it feels like 90% detours. I've seen drunk people walk in straighter lines than many data science classes.

So often, data science feels like mathematicians teaching math to wannabe mathematicians. Or programmers teaching programming to wannabe programmers. There's no connection to the big picture, to practical implementations, to generic competencies, to job requirements or to - you know - value creation.

Last week, while diving into PyTorch for a project in the Master's (for some reason, it's self study at my Uni), I came across fast.ai and suddenly everything clicked an started to make sense. Started the video course, my own project, bought the book and data science finally starts making sense. If only I'd known about this in 2018! It would have made learning so much more fun and productive and valuable!

For now I'll be doing a Master's related project in fast.ai and report the results here. It's a classroom-only Kaggle competition to train a model to recognize images of food items. My experience so far has been with tables and raw texts only, and working with images poses its own challenges, one of which is data storage. Tables live on a company server (where colleagues lovingly tend to them), raw texts are super memory efficient, but with images, it's different. Fast.ai showed the solution: store all training image files in folders with their label's name, and use a parent_label function to return the y-label. 

It's the simplicity of these solutions that brought back the enthusiasm to become a data scientist.

Another thing is that Fast.ai super-readable source code helps me become a better coder. You get used at instantiating objects whenever possible (for paths, for example) and doing vectorized functions whenever possible (like mapping). They explain it well, too

What I like most is the thinking they require you to do about your data. For this Kaggle competition, I want to use every available pixel to get the best classification, but in real life, that's actually not a good thing. Because your deployed model will have to work with real data, which can be at much lower resolutions. Being a psychologist, I'm a stern believer in Murphy's law (to be summarized as: "shit happens"), so this line of thinking is instantly appealing.

A related concept that I recognize from Natural Language Processing is the deliberate use of noise. From psychological point of view, it's really interesting to see that being confident is bad for learning. The computer must be taught to doubt, to be confused. The last thing we want is a macho-model (maybe that in itself is a reason we need enough women in data science!). So we're making life difficult for it by randomly picking parts of the model only, or rotating them, or changing colours, or whatever you can come up with. It's called data augmentation and it also helps to make most of a limited dataset.
